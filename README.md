# bella-whisper

bella-whisperæ˜¯ä¸€ç³»åˆ—åŸºäºOpenAI Whisperçš„å˜ä½“æ¨¡å‹ï¼Œä¸ºå®ç°ç²¾ç¡®çš„è¯­éŸ³è¯†åˆ«è½¬å†™è€Œè®¾è®¡ã€‚é€šè¿‡é‡‡ç”¨æ•°åƒå°æ—¶çš„é«˜è´¨é‡æ•°æ®è¿›è¡Œå¾®è°ƒè®­ç»ƒï¼Œbella-whisperåœ¨å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œç‰¹åˆ«æ˜¯åœ¨æˆ¿äº§ç»çºªé¢†åŸŸã€‚

## ğŸ“šç›®å½•
- [æ¨¡å‹åˆ—è¡¨](#æ¨¡å‹åˆ—è¡¨)
- [äº®ç‚¹](#äº®ç‚¹)
- [è¯„ä¼°ä¸åŸºå‡†](#è¯„ä¼°ä¸åŸºå‡†)
- [å®‰è£…ä¸è®¾ç½®](#å®‰è£…ä¸è®¾ç½®)
- [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
- [å¸¸è§é—®é¢˜è§£ç­”](#å¸¸è§é—®é¢˜è§£ç­”)
- [æ¨¡å‹è·å–ä¸è®¸å¯](#æ¨¡å‹è·å–ä¸è®¸å¯)
## ğŸ¤– æ¨¡å‹åˆ—è¡¨

| æ¨¡å‹åç§° | åŸºåº§æ¨¡å‹ | è®­ç»ƒæ—¶é—´ | Hugging Face ä»“åº“é“¾æ¥ |
|---------|---------|---------|-----------------------|
| bella-whisper-large-v3-turbo | whisper-large-v3-turbo | æœªå¼€æ”¾ | N/A |
| **bella-whisper-large-v3** | **whisper-large-v3** | **20241118** | **[é“¾æ¥](https://huggingface.co/bella-top/bella-whisper-large-v3)** |
| bella-whisper-medium | whisper-medium | æœªå¼€æ”¾ | N/A |
| bella-whisper-small | whisper-small | æœªå¼€æ”¾ | N/A |
| bella-whisper-tiny | whisper-tiny | æœªå¼€æ”¾ | N/A |


## âœ¨ äº®ç‚¹
- ğŸš€ **æ€§èƒ½ç¨³å®š**ï¼šåœ¨å¤šä¸ªé€šç”¨åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ç¨³å®šã€‚
- âœï¸ **æ ‡ç‚¹ç¬¦å·ä¼˜åŒ–**ï¼šè¾ƒå‡†ç¡®çš„æ ¹æ®è¯­å¢ƒçš„æ ‡ç‚¹è¡¥å…¨ã€‚
- ğŸ’¡ **ç‰¹å®šåœºæ™¯ä¼˜åŒ–**ï¼šæˆ¿äº§ç»çºªé¢†åŸŸç»è¿‡ç‰¹åˆ«ä¼˜åŒ–ã€‚
## ğŸ“Š è¯„ä¼°ä¸åŸºå‡†
æ¨¡å‹çš„æ€§èƒ½è¯„ä¼°æ˜¯è¡¡é‡æ¨¡å‹æ•ˆæœçš„å…³é”®ç¯èŠ‚ã€‚æˆ‘ä»¬é‡‡ç”¨æ ‡å‡†çš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¹¶åœ¨å…¬å¼€åŠè‡ªå®šä¹‰æµ‹è¯•é›†ä¸Šè¿›è¡Œä¸¥æ ¼çš„åŸºå‡†æµ‹è¯•ï¼Œ
bella-whisperåœ¨å¤šä¸ªæ ‡å‡†è¯­éŸ³è¯†åˆ«åŸºå‡†æµ‹è¯•ä¸­å±•ç°äº†å…¶ä¼˜è¶Šæ€§ã€‚
**æ¨ç†æ¡†æ¶**
æ¨ç†ä»£ç è§**transcribe.py**ã€‚

### å­—é”™è¯¯ç‡ (CER)
å¯¹äºä¸­æ–‡ç­‰åŸºäºå­—ç¬¦çš„è¯­è¨€ï¼Œè¿™æ˜¯æœ€é‡è¦çš„æŒ‡æ ‡ã€‚è®¡ç®—å…¬å¼ä¸ºï¼šCER = (æ›¿æ¢æ•°S + åˆ é™¤æ•°D + æ’å…¥æ•°I) / æ€»çœŸå®å­—æ•°Nã€‚CERè¶Šä½ï¼Œæ¨¡å‹æ€§èƒ½è¶Šå¥½ã€‚
#### é‡è¦è¯´æ˜
æ‰€æœ‰æµ‹è¯„æ•°æ®é‡‡æ ·ç‡å‡ä¸º16Kï¼Œä¸”åœ¨è®­ç»ƒæ•°æ®ä¸­å‡ä¸åŒ…å«ã€‚åœ¨è®¡ç®—CERä¹‹å‰ï¼Œé¢„æµ‹æ–‡æœ¬ (hypothesis) å’Œå‚è€ƒæ–‡æœ¬ (reference) éƒ½åº”ç»è¿‡ç›¸åŒçš„æ–‡æœ¬è§„èŒƒåŒ–å¤„ç†ï¼Œä»¥ç¡®ä¿æ¯”è¾ƒçš„å…¬å¹³æ€§ï¼Œå…·ä½“è§„åˆ™å¦‚ä¸‹ï¼š
**(1). å•ä½ç»Ÿä¸€è½¬æ¢**
| å•ä½ç¬¦å· | ä¸­æ–‡åç§° |
|:--------:|:--------:|
| ml, mL   | æ¯«å‡     |
| kL       | åƒå‡     |
| mÂ³, m3   | ç«‹æ–¹ç±³   |
| cmÂ³, cm3 | ç«‹æ–¹å˜ç±³ |
| ã¡, mÂ², m2 | å¹³æ–¹ç±³   |
| kmÂ², km2 | å¹³æ–¹åƒç±³ |
| cmÂ², cm2 | å¹³æ–¹å˜ç±³ |
| â„ƒ, Â°C    | æ‘„æ°åº¦   |
| K        | å¼€å°”æ–‡   |
| Â°F       | åæ°åº¦   |
| mm       | æ¯«ç±³     |
| cm       | å˜ç±³     |
| m        | ç±³       |
| km       | åƒç±³     |
| mg       | æ¯«å…‹     |
| g        | å…‹       |
| kg       | åƒå…‹     |
| t        | å¨       |
| s        | ç§’       |
| min      | åˆ†é’Ÿ     |
| h        | å°æ—¶     |
| W        | ç“¦       |
| kW       | åƒç“¦     |
| MW       | å…†ç“¦     |
| V        | ä¼       |
| Î©        | æ¬§å§†     |
| Hz       | èµ«å…¹     |
| kHz      | åƒèµ«å…¹   |
| MHz      | å…†èµ«å…¹   |
| Pa       | å¸•æ–¯å¡   |
| kPa      | åƒå¸•     |
| MPa      | å…†å¸•     |

**(2). æ•°å­—è½¬æ±‰å­—**
ä¾‹å¦‚ï¼š111 -> ä¸€ç™¾ä¸€åä¸€

**(3). å»é™¤æ ‡ç‚¹ç¬¦å·åŠç©ºæ ¼**
ä¸ºäº†æ›´ä¸¥æ ¼çš„å¯¹æ¯”ï¼Œæˆ‘ä»¬è¿˜ä¼šå»é™¤æ‰€æœ‰æ ‡ç‚¹ç¬¦å·å’Œç©ºæ ¼ã€‚

#### è¯„ä¼°æ–¹æ³•
ä½¿ç”¨ [jiwer](https://github.com/jitsi/jiwer) åº“æ¥è®¡ç®—CERã€‚

#### è¯„ä¼°ç»“æœ
ä»¥ä¸‹è¡¨æ ¼å±•ç¤ºäº†æœ¬é¡¹ç›®å¾®è°ƒæ¨¡å‹åœ¨ä¸€äº›æ ‡å‡†ä¸­æ–‡æµ‹è¯•é›†å’Œç‰¹å®šåœºæ™¯æµ‹è¯•é›†ä¸Šçš„æ€§èƒ½è¡¨ç°ï¼Œå¹¶ä¸åŸºçº¿æ¨¡å‹è¿›è¡Œå¯¹æ¯”ã€‚è¯·æ³¨æ„ï¼šæ‰€ç¤ºæ•°æ®ä¸ºç¤ºä¾‹ï¼Œå®é™…ç»“æœä¼šéšè®­ç»ƒæ•°æ®ã€è¶…å‚æ•°ã€è¯„ä¼°ç»†èŠ‚è€Œå˜åŒ–ï¼Œè¯·ä»¥é¡¹ç›®å®é™…å‘å¸ƒçš„æœ€æ–°ç»“æœä¸ºå‡†ã€‚

| æ•°æ®é›† |  bella-whisper-large-v3-20241118 | whisper-large-v3 | 
|:--------:|:--------:|:--------:|
| AISHELL-1 Test | 6.700% | 5.562% | 
| AISHELL-2 Test | 6.854% | 5.009% | 
| wenetspeech test_net | 10.908% | 9.474% |
| wenetspeech test_meeting | 11.469% | 18.916% | 
| [å†…éƒ¨] é€šç”¨æµ‹è¯„é›†-1 | 7.287% | 21.811% |
| [å†…éƒ¨] é€šç”¨æµ‹è¯„é›†-2  | 13.219% | 19.887% | 

#### ä¸€äº›ä¾‹å­
| Audio       | whisper-large-v3 | bella-whisper-large-v3-20241118 | åŸºå‡† |
|:--------:|:--------:|:--------:| :--------:|
| samples/sample1.wav   | èµ›åä¸»æ”»æœ±å»·éœæœ€æœ‰ä»·å€¼çƒå‘˜å’Œæœ€å—æ¬¢è¿çƒå‘˜| èµ›åä¸»æ”»**æœ±å©·**æˆ–æœ€æœ‰ä»·å€¼çƒå‘˜å’Œæœ€å—æ¬¢è¿çƒå‘˜ã€‚ | èµ›åä¸»æ”»æœ±å©·è·æœ€æœ‰ä»·å€¼çƒå‘˜å’Œæœ€å—æ¬¢è¿çƒå‘˜ |
| samples/sample2.wav   | æˆ‘ä»¬åº¦è¿‡äº†å¹³å®‰æ•…äº‹çš„ä¸€å¹´| æˆ‘ä»¬åº¦è¿‡äº†å¹³å®‰**æ— äº‹**çš„ä¸€å¹´ã€‚ | æˆ‘ä»¬åº¦è¿‡äº†å¹³å®‰æ— äº‹çš„ä¸€å¹´ |
| samples/sample3.wav   | è€Œæˆæ˜¯æœ€é‡è¦çš„ç½‘ç»œ| è€Œ**åŸå¸‚**æœ€é‡è¦çš„ç½‘ç»œã€‚ | è€ŒåŸå¸‚æœ€é‡è¦çš„ç½‘ç»œ |


#### æ•°æ®é›†è¯´æ˜
| æ•°æ®é›† | é‡‡æ ·ç‡ | æ•°æ®è§„æ¨¡ | è¯´æ˜ |
|:--------:|:--------:|:--------:|:--------:|
| AISHELL-1 Test | 16K | 10å°æ—¶ | å…¬å¼€çš„ä¸­æ–‡æ™®é€šè¯æœ—è¯»è¯­éŸ³æ•°æ®é›†çš„æµ‹è¯•éƒ¨åˆ† |
| AISHELL-2 Test | 16K | 4å°æ—¶ | å…¬å¼€çš„ä¸­æ–‡æ™®é€šè¯æœ—è¯»è¯­éŸ³æ•°æ®é›†çš„æµ‹è¯•éƒ¨åˆ†ã€‚|
| wenetspeech test_net | 16K | 12.6å°æ—¶ | ç”±æ¸…åå¤§å­¦è¯­éŸ³ä¸è¯­è¨€æŠ€æœ¯ä¸­å¿ƒ (CSLT) å‘å¸ƒçš„æ™®é€šè¯æœ—è¯»è¯­éŸ³æ•°æ®é›†|
| wenetspeech test_meeting | 16K | 15.2å°æ—¶ | ç”±æ¸…åå¤§å­¦è¯­éŸ³ä¸è¯­è¨€æŠ€æœ¯ä¸­å¿ƒ (CSLT) å‘å¸ƒçš„æ™®é€šè¯æœ—è¯»è¯­éŸ³æ•°æ®é›†|
| [å†…éƒ¨] é€šç”¨æµ‹è¯„é›†-1 | 16K | 5.1å°æ—¶ | çœŸå®ç¯å¢ƒä¸‹çš„é€šç”¨æ•°æ®é›†åˆ |
| [å†…éƒ¨] é€šç”¨æµ‹è¯„é›†-2  | 16K | 74.8å°æ—¶ | çœŸå®ç¯å¢ƒä¸‹çš„é€šç”¨æ•°æ®é›†åˆ |

## ğŸ”§ å®‰è£…ä¸è®¾ç½®

æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤æ¥è®¾ç½®å’Œå®‰è£…è¿è¡Œç¯å¢ƒã€‚æˆ‘ä»¬æä¾›å¦‚ä¸‹å‡ ç§æ¨ç†æ–¹å¼æ¥è¿›è¡Œæ¨¡å‹å®‰è£…å’Œè¿è¡Œã€‚

**ç¯å¢ƒå‡†å¤‡**
| ç¡¬ä»¶ç¯å¢ƒ | æ“ä½œç³»ç»Ÿ | å·²ç»éªŒè¯ç¯å¢ƒ |
|:--------:|:--------:|:--------:|
| gpu | linux | NVIDIA H20 + cuda_12.4 + Ubuntu20.04 |

**å…‹éš†ä»“åº“**
```bash
https://github.com/LianjiaTech/bella-whisper.git
cd bella-whisper
```

**ä¸åŒæ¨ç†æ–¹å¼å¯¹æ¯”**
| æ¨ç†æ–¹å¼ | æ¨¡å‹åŠ è½½é€Ÿåº¦ | æ¨ç†é€Ÿåº¦ | æ˜¾å­˜å ç”¨ |
|:--------:|:--------:|:--------:|:--------:|
| faster-whisper | 14.54ç§’ | 374.53ç§’ | 3.6G |
| vllm | 574.08ç§’ | 494.05ç§’  | 72.6G |
| huggingface transformers | 169.86ç§’ | 696.03ç§’ | 3.87G |

- ç¯å¢ƒï¼š
  - ç¡¬ä»¶ï¼šNVIDIA H20(95GB) * 1
- æ ·æœ¬ï¼šæ€»æ ·æœ¬æ•°é‡617ä¸ªï¼Œæ€»å…±æ—¶å¸¸30åˆ†é’Ÿã€‚
- ç»Ÿè®¡æ–¹æ³•ï¼šå¾ªç¯å–å‡ºæ¯ä¸ªéŸ³é¢‘ï¼Œè¿›è¡Œæ¨ç†ï¼Œè®¡ç®—æ€»æ—¶é•¿ã€‚

### 1. ä½¿ç”¨faster-whisperæ¨ç†
#### åˆ›å»º Python ç¯å¢ƒ
```bash
conda create -n bella-faster-whisper python=3.10
conda activate bella-faster-whisper
```
å®‰è£…ä¾èµ–

```bash
pip install -r framework/faster-whisper/requirements.txt
```

#### è¿è¡Œæ¨ç†

```python
from faster_whisper import WhisperModel
import torch

# åˆå§‹åŒ–æ¨¡å‹
model_id ="bella-top/bella-whisper-large-v3"
model = None
device = "cuda" if torch.cuda.is_available() else "cpu"
if torch.cuda.is_available():
    model = WhisperModel(model_id, device=device, compute_type="float16")
else:
    model = WhisperModel(model_id, device=device)
# è½¬å½•éŸ³é¢‘
audio_path = "sample1.wav"  # æ›¿æ¢ä¸ºä½ çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
segments, info = model.transcribe(audio_path,
                                 repetition_penalty=1.2,
                                 language="zh",
                                 beam_size=5,
                                 word_timestamps=True,
                                 condition_on_previous_text=False,
                                 chunk_length=10,
                                 vad_filter=False,
                                 vad_parameters=dict(
                                     min_silence_duration_ms=400,
                                     max_speech_duration_s=25,
                                     speech_pad_ms=400))

# æ‰“å°è½¬å½•ç»“æœ
full_text = ""
for segment in segments:
    full_text += segment.text

print(f"\nFull transcribed text: {full_text}")
```
### 2. ä½¿ç”¨vllmæ¨ç†
#### åˆ›å»º Python ç¯å¢ƒ
```bash
conda create -n bella-vllm-whisper python=3.10
conda activate bella-vllm-whisper
```
å®‰è£…ä¾èµ–

```bash
pip install -r framework/vllm/requirements.txt
```
#### è¿è¡Œæ¨ç†
```python
from vllm import LLM, SamplingParams
import librosa

# åˆ›å»º Whisper æ¨¡å‹å®ä¾‹
llm = LLM(
    model="bella-top/bella-whisper-large-v3",
    max_model_len=448,
    max_num_seqs=256,
    kv_cache_dtype="auto",
    dtype="float16",
    task="transcription",
    gpu_memory_utilization = 0.85,
    enforce_eager = False
)

# åŠ è½½æœ¬åœ°éŸ³é¢‘æ–‡ä»¶
audio_path = "sample1.wav"  # æ›¿æ¢ä¸ºä½ çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
audio, sample_rate = librosa.load(audio_path, sr=None)
    # å‡†å¤‡è¾“å…¥æç¤º
prompts = [
        {
            "prompt": "<|startoftranscript|>",
            "multi_modal_data": {
                "audio": (audio, sample_rate),
            },
        }
    ]

    # è®¾ç½®é‡‡æ ·å‚æ•°
sampling_params = SamplingParams(
        temperature=0,
        top_p=1.0,
        max_tokens=500,
    )

# å¼€å§‹æ¨ç†
outputs = llm.generate(prompts, sampling_params)

# æ‰“å°ç»“æœ
for output in outputs:
    generated_text = output.outputs[0].text
    print(f"Generated text: {generated_text!r}")
```
### 3. ä½¿ç”¨huggingface transformersæ¨ç†
#### åˆ›å»º Python ç¯å¢ƒ
```bash
conda create -n bella-huggingface-whisper python=3.10
conda activate bella-huggingface-whisper
```
å®‰è£…ä¾èµ–

```bash
pip install -r framework/huggingface/requirements.txt
```
#### è¿è¡Œæ¨ç†
```python
import torch
import librosa
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline

device = "cuda:0" if torch.cuda.is_available() else "cpu"
torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

model_id = "bella-top/bella-whisper-large-v3"

# åŠ è½½æ¨¡å‹å’Œå¤„ç†å™¨
model =AutoModelForSpeechSeq2Seq.from_pretrained(
    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True
)
model.to(device)

processor = AutoProcessor.from_pretrained(model_id)

# åˆ›å»ºæ¨ç†ç®¡é“
pipe = pipeline(
    "automatic-speech-recognition",
    model=model,
    tokenizer=processor.tokenizer,
    feature_extractor=processor.feature_extractor,
    torch_dtype=torch_dtype,
    device=device,
)

# åŠ è½½æœ¬åœ°éŸ³é¢‘æ–‡ä»¶
audio_path = "sample1.wav"  # æ›¿æ¢ä¸ºä½ çš„éŸ³é¢‘æ–‡ä»¶è·¯å¾„
audio, sample_rate = librosa.load(audio_path, sr=16000)  # ç¡®ä¿é‡‡æ ·ç‡ä¸º 16kHz

# ä½¿ç”¨ç®¡é“è¿›è¡Œæ¨ç†
result = pipe(audio)
print("Transcription:", result["text"])
```
## â“ å¸¸è§é—®é¢˜è§£ç­”
æš‚æ— 
## ğŸ”’ æ¨¡å‹è·å–ä¸è®¸å¯
 bella-whisperæ¨¡å‹å¯ä»¥é€šè¿‡ Hugging Face Model Hub è·å–ã€‚ä½¿ç”¨å‰è¯·ç¡®ä¿æ‚¨æ‹¥æœ‰ Hugging Face è´¦æˆ·ï¼Œå¹¶å·²æ¥å—æ¨¡å‹çš„ä½¿ç”¨è®¸å¯ã€‚æ‚¨å¯èƒ½éœ€è¦ä½¿ç”¨ Hugging Face è®¿é—®ä»¤ç‰Œæ¥ä¸‹è½½æ¨¡å‹ã€‚

é¡¹ç›®ä»£ç åŸºäº [MIT è®¸å¯è¯](https://opensource.org/licenses/MIT) å¼€æºã€‚
